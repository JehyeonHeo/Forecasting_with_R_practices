# Chapter 12

```{r echo=FALSE, message=FALSE, warning=FALSE, Load_packages}

library(fpp2)

```

## Forecast combinations examples

```{r echo=FALSE, message=FALSE, warning=FALSE, Forecast_combinations}

# It is an example using auscafe data. They have information about monthly expenditure on eating out in Australia, from April 1982 to September 2017. I'm going to get forecasts from the following models: ETS, ARIMA, STL-ETS, NNAR, and TBATS. And we compare the results using the last 5 years (60 months) of observations.
auscafe.train <- window(auscafe, end=c(2012,9))
h <- length(auscafe) - length(auscafe.train)

# forecast using several models.
auscafe_ETS <- forecast(ets(auscafe.train), h=h)
auscafe_ARIMA <- forecast(
  auto.arima(auscafe.train, lambda=0, biasadj=TRUE), h=h
  )
auscafe_STL <- stlf(
  auscafe.train, lambda=0, h=h, biasadj=TRUE
  )
auscafe_NNAR <- forecast(nnetar(auscafe.train), h=h)
auscafe_TBATS <- forecast(
  tbats(auscafe.train, biasadj=TRUE), h=h
  )
auscafe_Combination <- (
  auscafe_ETS$mean + 
  auscafe_ARIMA$mean + 
  auscafe_STL$mean + 
  auscafe_NNAR$mean + 
  auscafe_TBATS$mean
  )/5

# plot the result
autoplot(auscafe) +
  autolayer(auscafe_ETS$mean, series="ETS") +
  autolayer(auscafe_ARIMA$mean, series="ARIMA") +
  autolayer(auscafe_STL$mean, series="STL") +
  autolayer(auscafe_NNAR$mean, series="NNAR") +
  autolayer(auscafe_TBATS$mean, series="TBATS") +
  autolayer(auscafe_Combination, series="Combination") +
  xlab("Year") + ylab("$ billion") +
  ggtitle("Australian monthly expenditure on eating out")

# get accuracy for each model
c(
  ETS=accuracy(
    auscafe_ETS, auscafe
    )["Test set","RMSE"],
  ARIMA=accuracy(
    auscafe_ARIMA, auscafe
    )["Test set","RMSE"],
  `STL-ETS`=accuracy(
    auscafe_STL, auscafe
    )["Test set","RMSE"],
  NNAR=accuracy(
    auscafe_NNAR, auscafe
    )["Test set","RMSE"],
  TBATS=accuracy(
    auscafe_TBATS, auscafe
    )["Test set","RMSE"],
  Combination=accuracy(
    auscafe_Combination, auscafe
    )["Test set","RMSE"]
  )

# When I get accuracy using RMSE, the forecasts from combinations of models yielded lowest error. TBATS did particularly well with this series, but the combination approach was even better.
# Combination approach generally improves forecast accuracy.

```


## Dealing with weekly data example

```{r echo=FALSE, message=FALSE, warning=FALSE, Weekly_data}

# The simplest approach is to use an STL decomposition to the seasonal component along with a non-seasonal method applied to the seasonally adjusted component of data.
gasoline %>% stlf() %>% autoplot()

# An alternative approach is to use a dynamic harmonic regression model. Example using gasoline data again.
gasoline_dreg.best <- list(aicc=Inf)

for(K in seq(26)){
  gasoline_dreg <- auto.arima(
    #substitute seasonal component with Fourier terms.
    gasoline, 
    xreg=fourier(gasoline, K=K), 
    seasonal=FALSE
    )
  
  if(gasoline_dreg$aicc < gasoline_dreg.best$aicc)
  {
    gasoline_dreg.best <- gasoline_dreg
    gasoline_K.best <- K
  }
}

# forecast the next 2 years of data. If I assume that 1 year is about 52 weeks, forecast horizon(h) is 104.
fc_gasoline_dreg.best <- forecast(
  gasoline_dreg.best, 
  xreg=fourier(gasoline, K=gasoline_K.best, h=104)
  )

autoplot(fc_gasoline_dreg.best)

# A third approach is the TBATS model. This was the subject of Question 11.2.
gasoline_tbats <- tbats(gasoline)

checkresiduals(gasoline_tbats)
# The residuals aren't like white noise.

fc_gasoline_tbats <- forecast(gasoline_tbats)
autoplot(fc_gasoline_tbats)
# The forecasts from above 3 methods are similar to each other.
# At the question 11.2, I thought that the dynamic harmonic regression model will be best for the data because of unlinearity in trend.

# If there's an unlinearity of trend or irregular seasonality in the data, dynamic regression model with dummy variable(s) will be the only choice. This fact can be applied to daily or sub-daily data, too.

```

