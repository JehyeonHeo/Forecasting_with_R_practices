# Chapter 9

```{r echo=FALSE, message=FALSE, warning=FALSE, Load_packages}

library(fpp2)
library(xlsx)

```

1. Consider monthly sales and advertising data for an automotive parts company (data set advert).

```{r echo=FALSE, message=FALSE, warning=FALSE, Question1}

# a. Plot the data using autoplot. Why is it useful to set facets=TRUE?
str(advert)
head(advert)

autoplot(advert, facets = TRUE)
# Can see the advertising expenditure data and sales volume data in different panels. facets = TRUE option can plot the subsets of data in each panel.

# b. Fit a standard regression model yt = a + b*xt + nt where yt denotes sales and xt denotes advertising using the tslm() function.
advert_tslm <- tslm(sales ~ advert, data = advert)

# c. Show that the residuals have significant autocorrelation.
checkresiduals(advert_tslm)
# The residuals have significant autocorrelations at lag 1 and 2.

# d. What difference does it make you use the function instead:
#  Arima(advert[,"sales"], xreg=advert[,"advert"], order=c(0,0,0))
advert_dreg.0.0.0 <- Arima(
  advert[, "sales"], xreg = advert[, "advert"],
  order = c(0, 0, 0)
)

checkresiduals(advert_dreg.0.0.0)
advert_tslm$residuals - advert_dreg.0.0.0$residuals
# The residuals from dynamic regression model are almost same as the residuals from tslm function.
# But when I use Arima function, I can do ARIMA modeling for residuals by designating order.

# e. Refit the model using auto.arima(). How much difference does the error model make to the estimated parameters? What ARIMA model for the errors is selected?
advert_dreg.auto <- auto.arima(
  advert[, "sales"], xreg = advert[, "advert"]
)

advert_dreg.0.0.0
# error model coefficients:
# intercept : 78.7343, slope_advert : 0.5343

advert_dreg.auto
# error model : ARIMA(0, 1, 0)
# xreg : 0.5063

# f. Check the residuals of the fitted model.
checkresiduals(advert_dreg.auto)
# The residuals are like white noise.

autoplot(advert[, "sales"], series = "Data") +
  geom_line(color = "red", size = 1) +
  autolayer(advert_dreg.auto$fitted, size = 1, series = "Dynamic Regression fitted values") +
  autolayer(advert_tslm$fitted.values, size = 1, series = "Linear Regression fitted values") +
  ylab("Sales volume")

accuracy(advert_dreg.0.0.0)
accuracy(advert_dreg.auto)
# The plot above and most of errors show that dynamic regression with ARIMA(0, 1, 0) error model was better than the linear regression model.

# g. Assuming the advertising budget for the next six months is exactly 10 units per month, produce and plot sales forecasts with prediction intervals for the next six months.
fc_advert_dreg.auto <- forecast(
  advert_dreg.auto, h = 6,
  xreg = rep(10, 6)
  )

autoplot(fc_advert_dreg.auto)
# The forecasts are like the result of naive method.

```


2. This exercise uses data set huron giving the level of Lake Huron from 1875-1972.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question2}

# a. Fit a piecewise linear trend model to the Lake Huron data with a knot at 1920 and an ARMA error structure.
autoplot(huron)

t <- time(huron)
t.knot <- 1920
# piecewise time variable. Before knot year(1920), all values are 0, but after the year, the values increase as year increases.
t.pw <- ts(pmax(0, t - t.knot), start = t[1])
huron_xreg <- cbind(t = t, t.pw = t.pw)
huron_dreg.auto <- auto.arima(
  huron, xreg = huron_xreg
)

huron_dreg.auto
# Regression with AR(2) errors model.

autoplot(huron) +
  autolayer(huron_dreg.auto$fitted)

# b. Forecast the level for the next 30 years.
h <- 30
t.new <- t[length(t)] + seq(h)
t.pw.new <- t.pw[length(t.pw)] + seq(h)
newdata <- cbind(t = t.new, t.pw = t.pw.new) %>% as.data.frame()

fc_huron_dreg.auto <- forecast(
  huron_dreg.auto, xreg = newdata, h = 30
)

autoplot(fc_huron_dreg.auto)
# The level of lake Huron was forecasted to decrease fastly first and then to increase slowly.

checkresiduals(fc_huron_dreg.auto)
# The residuals are like white noise.

```


3. This exercise concerns motel: the total monthly takings from accommodation and the total room nights occupied at hotels, motels, and guest houses in Victoria, Australia, between January 1980 and June 1995. Total monthly takings are in thousands of Australian dollars; total room nights occupied are in thousands.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question3}

# a. Use the data to calculate the average cost of a night's accommodation in Victoria each month.
autoplot(motel, facets = TRUE)

avg.cost_night.room <- motel[, "Takings"] / motel[, "Roomnights"]
autoplot(avg.cost_night.room)
# Average cost of a night's accomodation in Victoria increased fastly until 1990, and then just oscillated without increasing until 1995.

# b. Estimate the monthly CPI.
# I'll use ARIMA model to estimate monthly CPI.
# I'll use log transformation before fitting the model using lambda = 0 option.
CPI_autoarima <- auto.arima(
  motel[, "CPI"], lambda = 0
)

autoplot(motel[, "CPI"]) +
  autolayer(CPI_autoarima$fitted)
# Fitted values of ARIMA model show the estimates of monthly CPI.

# c. Produce time series plots of both variables and explain why logarithms of both variables need to be taken before fitting any models.
autoplot(avg.cost_night.room)
autoplot(CPI_autoarima$fitted)
# logarithms can make the variations almost same for all the time. It can also make slowly increasing data linearly. Therefore it would be better for the above 2 variables to take logarithms before fitting any model.

# d. Fit an appropriate regression model with ARIMA errors. Explain your reasoning in arriving at the final model.
# fit avg.cost_night.room using linear regression model after log transformation. I will use fitted values of CPI_autoarima as a regressor.
avg.cost_night.room_tslm <- tslm(
  avg.cost_night.room ~ CPI_autoarima$fitted,
  lambda = 0
)

checkresiduals(avg.cost_night.room_tslm)
# The residuals aren't like white noise. ARIMA model can be useful to explain the autocorrelations in the residuals. Therefore I'm going to fit with dynamic regression model.
# as I said in part c, it would be better to use logarithm transformation before fitting the model.

avg.cost_night.room_dreg.auto <- auto.arima(
  avg.cost_night.room, xreg = CPI_autoarima$fitted,
  lambda = 0, stepwise = FALSE, approximation = FALSE
)

checkresiduals(avg.cost_night.room_dreg.auto)
# The residuals are like white noise.

# The unit of average cost is thousands of AU$. Therefore make a function to transform average cost value to have AU$ unit. I'm going to use the function in plot labeling.
formatter1000 <- function(x){ 
  scales::dollar(x*1000)
}

autoplot(avg.cost_night.room, series = "Data") +
  autolayer(avg.cost_night.room_dreg.auto$fitted, series = "Dynamic regression model") +
  autolayer(avg.cost_night.room_tslm$fitted.values, series = "Linear regression model") +
  ylab("Avg.cost(AU$)") +
  ggtitle("Average cost of a night's accomodation",
          subtitle = "In Victoria, Australia") +
  theme(plot.subtitle = element_text(size=13)) +
  scale_y_continuous(labels = formatter1000)
# dynamic regression model after log transformation fits better than the linear regression model.

# e. Forecast the average price per room for the next twelve months using your fitted model. (Hint: You will need to produce forecasts of the CPI figures first.)
fc_CPI_autoarima <- forecast(
  CPI_autoarima, h = 12
)

fc_avg.cost_night.room_dreg.auto <- forecast(
  avg.cost_night.room_dreg.auto,
  xreg = fc_CPI_autoarima$mean,
  h = 12
)

autoplot(fc_avg.cost_night.room_dreg.auto)
# It is forecasted that the average cost of a night's accomodation in Victoria, Australia will be increased a little with oscillation.

```


4. We fitted a harmonic regression model to part of the gasoline series in Exercise 6 in Section 5.10. We will now revisit this model, and extend it to include more data and ARMA errors.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question4}

# a. Using tslm, fit a harmonic regression with a piecewise linear time trend to the full gasoline series. Select the position of the knots in the trend and the appropriate number of Fourier terms to include by minimizing the AICc or CV value.
str(gasoline)
head(gasoline)

autoplot(gasoline)
# It looked like this data can be divided into 3 parts. First part is increase from the 1991(start) to June, 2007. Second part is decrease from July, 2007 to the end of 2012. Third part is increase from 2013 to 2017(end). 
# the data is weekly data. Therefore I'll set first knot as 2007.5 and second knot as 2013.
t <- time(gasoline)
t.knot1 <- 2007.5
t.knot2 <- 2013
t.pw1 <- ts(pmax(0, t - t.knot1), start = t[1],
            frequency = 365.25/7)
t.pw2 <- ts(pmax(0, t - t.knot2), start = t[1],
            frequency = 365.25/7)

# Set default AICc as infinite and default number of pairs as 0.
AICc <- Inf
K_min.Aicc <- 0

# use for loop to find the harmonic regression model which yields least AICc. Maximum number of repetition is 26 times because the maximum number of pairs is less than a half of the number of weeks in a year, 52.18.
for(num in c(1:26)){
  gasoline_tslm <- tslm(
    gasoline ~ trend + t.pw1 + t.pw2 + fourier(
      gasoline, K = num
    )
  )
  AICc_value <- CV(gasoline_tslm)["AICc"]
  
  if(AICc > AICc_value){
    AICc <- AICc_value
  }else{
    K_min.Aicc <- num
    break 
  }
}

K_min.Aicc
# 11 Fourier pairs were chosen.
gasoline_tslm
# 26 variables including intercept were used.

autoplot(gasoline) +
  geom_line(color = "gray") +
  autolayer(gasoline_tslm$fitted.values)
# fitted values are somewhat similar to the data.

# b. Now refit the model using auto.arima to allow for correlated errors, keeping the same predictor variables as you used with tslm.

# gasoline_autoarima <- auto.arima(
#   gasoline, xreg = cbind(t=t, t.pw1=t.pw1,  t.pw2=t.pw2, Fourier = fourier(gasoline, K = 11)))
# It takes lots of time to find the optimal model. Therefore I'm going to make ARIMA(4, 0, 2)(1, 0, 0)[52] error model designating the order in the function.
gasoline_autoarima <- Arima(
  gasoline, xreg = cbind(t=t, t.pw1=t.pw1,  t.pw2=t.pw2, Fourier = fourier(gasoline, K = 11)),
  order = c(4, 0, 2), seasonal = c(1, 0, 0)
  )

gasoline_autoarima
# ARIMA(4, 0, 2)(1, 0, 0)[52] error model was chosen.

# c. Check the residuals of the final model using the checkresiduals() function. Do they look sufficiently like white noise to continue? If not, try modifying your model, or removing the first few years of data.
checkresiduals(gasoline_autoarima)
# The residuals aren't like white noise.

# I'll make dynamic regression model using data from 2000.
gasoline.from2000 <- window(gasoline, start = 2000)
t.from2000 <- window(t, start = 2000)
t.pw1.from2000 <- window(t.pw1, start = 2000)
t.pw2.from2000 <- window(t.pw2, start = 2000)

# find the number of Fourier pairs for new data. 
AICc <- Inf
K_min.Aicc <- 0

for(num in c(1:26)){
  gasoline.from2000_tslm <- tslm(
    gasoline.from2000 ~ trend + t.pw1.from2000 + t.pw2.from2000 + fourier(
      gasoline.from2000, K = num
    )
  )
  AICc_value <- CV(gasoline.from2000_tslm)["AICc"]
  
  if(AICc > AICc_value){
    AICc <- AICc_value
  }else{
    K_min.Aicc <- num
    break 
  }
}

K_min.Aicc
# still 11 Fourier pairs were chosen.
gasoline.from2000_tslm
# again, 26 variables including intercept were used.

# bind new data regressors to a variable.
xreg.from2000 <- cbind(
  t = t.from2000, 
  t.pw1 = t.pw1.from2000, 
  t.pw2 = t.pw2.from2000,
  Fourier = fourier(
    gasoline.from2000, K = 11
    )
  )

# It also takes some minutes to run.
gasoline.from2000_autoarima <- auto.arima(
  gasoline.from2000,
  xreg = xreg.from2000
)

gasoline.from2000_autoarima
# ARIMA(1, 0, 1)(1, 0, 1)[52] error model was chosen.

checkresiduals(gasoline.from2000_autoarima)
# The residuals aren't still like white noise.
ggtsdisplay(gasoline.from2000_autoarima$residuals)
# I think that if I use more autoregressive terms, I can make the residuals like white noise even if the likelihood will be worse.

# The result when I tried ARIMA(6, 0, 1) error model.
gasoline.from2000_arima.6.0.1 <- Arima(
  gasoline.from2000,
  xreg = xreg.from2000,
  order = c(6, 0, 1)
)

checkresiduals(gasoline.from2000_arima.6.0.1)
# now residuals are like white noise.
# I finally got white-noise-like residuals by using fewer data and modifying the model bearing worse likelihood.

# d. Once you have a model with white noise residuals, produce forecasts for the next year.
h = 52
t.new <- t.from2000[length(t.from2000)] + seq(h)/365.25
t.pw1.new <- t.pw1.from2000[length(t.pw1.from2000)] + seq(h)/365.25
t.pw2.new <- t.pw2.from2000[length(t.pw2.from2000)] + seq(h)/365.25

xreg.new <- cbind(
  t = t.new, 
  t.pw1 = t.pw1.new, 
  t.pw2 = t.pw2.new,
  Fourier = fourier(
    gasoline.from2000, K = 11, h = h
    )
  )

fc_gasoline.from2000_arima.6.0.1 <- forecast(
  gasoline.from2000_arima.6.0.1,
  xreg = xreg.new,
  h = h
)

autoplot(fc_gasoline.from2000_arima.6.0.1)
# It looked like the forecasts are reasonable.

```


6. For the retail time series considered in earlier chapters:
a. Develop an appropriate dynamic regression model with Fourier terms for the seasonality. Use the AIC to select the number of Fourier terms to include in the model. (You will probably need to use the same Box-Cox transformation you identified previously.)
b. Check the residuals of the fitted model. Does the residual series look like white noise?
c. Compare the forecasts with those you obtained earlier using alternative models.

### Question 5 isn't related with coding that I didn't include it in here.