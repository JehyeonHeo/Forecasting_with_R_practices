# Chapter 5

```{r echo=FALSE, message=FALSE, warning=FALSE, Load_packages}

library(fpp2)

```

1. Daily electricity demand for Victoria, Australia, during 2014 is contained in elecdaily. The data for the first 20 days can be obtained as follows.

daily20 <- head(elecdaily,20)

```{r echo=FALSE, message=FALSE, warning=FALSE, Question1}

# I need to make elecdaily because existing data is elecdemand and it has half-hourly electricity demand for Victoria, Australia.
# Aggregate demand by sum and workday and temperature by mean. Set nfrequency as 365 to aggregate data for each day.
elecdaily <- ts.union(
  aggregate(elecdemand[, "Demand"], nfrequency = 365, FUN = sum),
  aggregate(elecdemand[, !colnames(elecdemand) %in% c("Demand")], nfrequency = 365, FUN = mean)
  )
# Need to change the names of columns after aggregating.
colnames(elecdaily) <- colnames(elecdemand)

# It will be easier to aggregate if I know the index of the want-to-remove column
#elecdemand[, -1]
#elecdemand[, -c(2,3)]

daily20 <- head(elecdaily, 20)
daily20

# a. Plot the data and find the regression model for Demand with temperature as an explanatory variable. Why is there a positive relationship?
autoplot(daily20)

# Use tslm function to find the regression model
tslm_Dem_Temp <- tslm(Demand ~ Temperature, data = daily20)
tslm_Dem_Temp

# There is a positive relationship between the two variables. It looked like it happened because of air conditioner and fan. It's likely that as temperature increased, people wanted to run them and it increased the demand of electricity

# A scatter plot of Demand against Temperature is shown below with the estimated regression line. This graph shows the positive relation a lot more clearly
daily20 %>%
  as.data.frame() %>%
  ggplot(aes(x=Temperature, y=Demand)) +
    ylab("Electricity Demand") +
    xlab("Temperature") +
    geom_point() +
    geom_smooth(method="lm", se=FALSE)

# b. Produce a residual plot. Is the model adequate? Are there any outliers or influential observations?
checkresiduals(tslm_Dem_Temp$residuals)
# I think that this model is adequate because residuals aren't correlated with each other. But there was an outlier.

# c. Use the model to forecast the electricity demand that you would expect for the next day if the maximum temperature was 15 and compare it with the forecast if the with maximum temperature was 35. Do you believe these forecasts?
fc_Dem_Temp <- forecast(tslm_Dem_Temp, 
  newdata=data.frame(Temperature=c(15,35)))
fc_Dem_Temp
# I believe these forecasts because the temperature values were near the range of temperatures in the data

# d. Give prediction intervals for your forecasts. The following R code will get you started:
# 80% intervals
fc_Dem_Temp$upper[, 1]
fc_Dem_Temp$lower[, 1]
# 95% intervals
fc_Dem_Temp$upper[, 2]
fc_Dem_Temp$lower[, 2]

# e. Plot Demand vs Temperature for all of the available data in elecdaily. What does this say about your model?
elecdaily %>%
  as.data.frame() %>%
  ggplot(aes(x=Temperature, y=Demand)) +
    ylab("Electricity Demand") +
    xlab("Temperature") +
    geom_point() +
    geom_smooth(method="lm", se=FALSE)
# The result plot shows that the model was made with few data points. It could've explained the data of the first 20 days well, but it wasn't right model for total data points

```


2. Data set mens400 contains the winning times (in seconds) for the men's 400 meters final in each Olympic Games from 1896 to 2016.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question2}

# a. Plot the winning time against the year. Describe the main features of the plot.
autoplot(mens400)
# Feature1. Winning times in Olympic men's 400m track final had the trend of decreasing as time went on.
# Feature2. Missing values occured.

# b. Fit a regression line to the data. Obviously the winning times have been decreasing, but at what average rate per year?
# Extract time part from mens400 time series to do linear modeling.
time_mens400 <- time(mens400)
tslm_mens400 <- tslm(mens400 ~ time_mens400, 
                     data = mens400)

# Show data with regression line
autoplot(mens400) +
  geom_abline(slope = tslm_mens400$coefficients[2],
              intercept = tslm_mens400$coefficients[1],
              colour = "red")

# Get time decreasing rate
tslm_mens400$coefficients[2]
# The winning times have been decreasing at average rate of 0.06457 second per year.

# c. Plot the residuals against the year. What does this indicate about the suitability of the fitted line?
cbind(Time = time_mens400, 
      Residuals = tslm_mens400$residuals) %>%
  as.data.frame() %>%
  ggplot(aes(x = Time, y = Residuals)) +
    geom_point() +
    ylab("Residuals of Regression Line(Unit:s)")
# The residual plot shows that the regression model generally fitted well to the data. I can check it using checkresiduals function, too.
checkresiduals(tslm_mens400)

# d. Predict the winning time for the men's 400 meters final in the 2020 Olympics. Give a prediction interval for your forecasts. What assumptions have you made in these calculations?
# I used lm function here to get prediction interval through forecast function. Forecast function can't calculate prediction interval when there is any missing values in the data.
lm_mens400 <- lm(
  mens400 ~ time_mens400, 
  data = mens400,
  na.action = na.exclude
  )

fc_mens400 <- forecast(
  lm_mens400, 
  newdata = data.frame(time_mens400 = 2020)
  )

autoplot(mens400) +
  autolayer(fc_mens400, PI = TRUE)

# Get 80% and 95% prediction intervals
fc_mens400$upper
fc_mens400$lower

# 80% interval is from 40.45 to 43.63
# 95% interval is from 39.55 to 44.53
# But we need to consider that they were calculated from the assumption that the residuals from model were normally distributed. But we saw from the result of checkresiduals function that it isn't true.

```


3. Type easter(ausbeer) and interpret what you see.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question3}

help("ausbeer")
head(ausbeer)
str(ausbeer)
# Quarterly Australian beer production data. There are 218 data points.

time(ausbeer)[c(1, length(ausbeer))]
# start is 1st quarter of 1956 and the last is the 2nd quarter of 2010.

easter(ausbeer)
# easter function returns a vector of 0's or 1's or fractional parts in the observed time period. If full Easter holidays are in a time period, it returns 1, and returns 0 if there isn't any. If the holidays are extended from a period to the other, easter function returns fractional portions to each of them.

```


5. The data set fancy concerns the monthly sales figures of a shop which opened in January 1987 and sells gifts, souvenirs, and novelties. The shop is situated on the wharf at a beach resort town in Queensland, Australia. The sales volume varies with the seasonal population of tourists. There is a large influx of visitors to the town at Christmas and for the local surfing festival, held every March since 1988. Over time, the shop has expanded its premises, range of products, and staff.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question5}

# a. Produce a time plot of the data and describe the patterns in the graph. Identify any unusual or unexpected fluctuations in the time series.
autoplot(fancy)
head(fancy, 50)
# Sales generally increased from January to December. Sales increased dramatically in December. Sales in December increased as time went on, but in 1991, there was decresing. In most years, there were also unexpected increases in March but the size of increases were a lot smaller than what happened in December.

# b. Explain why it is necessary to take logarithms of these data before fitting a model.
# The size of the seasonal variations should be almost same across the whole series to fit a model. Fancy data shows that seasonal variations increased exponentially. Therefore it is necessary to take logarithms of the data.

# c. Use R to fit a regression model to the logarithms of these sales data with a linear trend, seasonal dummies and a "surfing festival" dummy variable.
# I'll do Box-Cox transformation for fancy data
lambda <- BoxCox.lambda(fancy)

# make "surfing_festival" dummy variable using time index of fancy. The value is 1 if the year is equal to or above 1988 and the month is March.
Time <- time(fancy)
surfing_festival <- c()
for(i in 1:length(Time)){
  month <- round(12*(Time[i] - floor(Time[i]))) + 1
  year <- floor(Time[i])
  if(year >= 1988 & month == 3){
    surfing_festival[i] <- 1
  } else {
    surfing_festival[i] <- 0
  }
}
# If I'd made surfing_festival as a list, I should've needed to use unlist function to make it as atomic vector, not nested list. tslm function can get vector or factor but it cannot get nested list.

tslm_BoxCox_fancy <- tslm(
  fancy ~ trend + season + surfing_festival,
  lambda = lambda
  )
# But when I added surfing_festival dummy variable, the interval of the residuals increased.

# d. Plot the residuals against time and against the fitted values. Do these plots reveal any problems with the model?
autoplot(tslm_BoxCox_fancy$residuals)
# Residuals show pattern against time. It means that there is correlation between residuals and time.

cbind(Residuals = tslm_BoxCox_fancy$residuals,
      Fitted_values = tslm_BoxCox_fancy$fitted.values) %>%
  as.data.frame() %>%
  ggplot(aes(x = Fitted_values,
             y = Residuals)) +
    geom_point()
# The size of residuals changed as we move along the x-axis. It means that there may be heteroscedacity in the errors which means that the variance of the residuals may not be constant. Maybe better transformation of the data is required.

# e. Do boxplots of the residuals for each month. Does this reveal any problems with the model?
cbind.data.frame(
    Month = factor(
      month.abb[round(12*(Time - floor(Time)) + 1)],
      labels = month.abb,
      ordered = TRUE
    ),
    Residuals = tslm_BoxCox_fancy$residuals
    ) %>%
  ggplot(aes(x = Month,
             y = Residuals)) +
    geom_boxplot()
# If vectors are combined by cbind function, the type of the result is matrix, which should hold one type of data. If I need to make the columns to have different data types, I need to use cbind.data.frame function instead. Instead, if I still use cbind function, I need to use as.numeric function in mapping of ggplot.
# If the mapping of boxplot is (factor x factor), it would be difficult to see any box because boxplot function can't aggregate factor type data. The result would be looked like a scatter plot.

# To see the change of the residuals for each month, I use ggsubseriesplot function.
ggsubseriesplot(tslm_BoxCox_fancy$residuals)

# The distribution of the residuals were unsymetrical for some months. And for some month, the median of the residuals weren't 0(mean should be 0 for all months because getting the minimum SSE means getting mean). Residuals with such properties can't have normal distribution, which will make it difficult to get prediction interval.

# f. What do the values of the coefficients tell you about each variable?
tslm_BoxCox_fancy$coefficients
# The model has positive trend. It means that as time went on, the sales increased generally. And all seasonal variables are positive. It means that the sales was minimum on January and the sales of the other months were greater than January for most of years. Finally, surfing_festival variable got 0.51 which isn't small compared to the others. It means that there were increased sales in March when surfing festival happened.

# g. What does the Breusch-Godfrey test tell you about your model?
checkresiduals(tslm_BoxCox_fancy)
# The p value of the test is less than 0.05. It means that the residuals can be distinguished from white noise. The residuals can be correlated with each other.

# h. Regardless of your answers to the above questions, use your regression model to predict the monthly sales for 1994, 1995, and 1996. Produce prediction intervals for each of your forecasts.
# make surfing festival data for the months of 1994 to 1996.
future_fancy <- rep(0, 36)
for(i in 1:36){
  if(i %% 12 == 3){
    future_fancy[i] <- 1
  }
}
# make future data as time series.
future_fancy <- ts(data = future_fancy,
                   start = 1994,
                   end = c(1996, 12),
                   frequency = 12)

# forecast
fc_tslm_BoxCox_fancy <- forecast(
  tslm_BoxCox_fancy,
  newdata = data.frame(Time = time(future_fancy),
                       surfing_festival = future_fancy)
)

# plot the forecast
autoplot(fc_tslm_BoxCox_fancy)

# show prediction interval
fc_tslm_BoxCox_fancy$upper
fc_tslm_BoxCox_fancy$lower
# The intervals on December were especially large.

# i. Transform your predictions and intervals to obtain predictions and intervals for the raw data.
tslm_fancy <- tslm(
  fancy ~ trend + season + surfing_festival
  )

fc_tslm_fancy <- forecast(
  tslm_fancy,
  newdata = data.frame(Time = time(future_fancy),
                       surfing_festival = future_fancy)
)

autoplot(fc_tslm_fancy)

fc_tslm_fancy$upper
fc_tslm_fancy$lower
# The predictions are a lot less accurate than the transformed version.

# j. How could you improve these predictions by modifying the model?
# I could've improved the predictions by using Box-Cox transformation, one of lograrithm transfortion method. By using the method, the predictions could follow the exponential growth trend of the sales better.

```


6. The gasoline series consists of weekly data for supplies of US finished motor gasoline product, from 2 February 1991 to 20 January 2017. The units are in "thousand barrels per day". Consider only the data to the end of 2004.

a. Fit a harmonic regression with trend to the data. Experiment with changing the number Fourier terms. Plot the observed gasoline and fitted values and comment on what you see.
b. Select the appropriate number of Fourier terms to include by minimizing the AICc or CV value.
c. Check the residuals of the final model using the checkresiduals() function. Even though the residuals fail the correlation tests, the results are probably not severe enough to make much difference to the forecasts and prediction intervals. (Note that the correlations are relatively small, even though they are significant.)
d. To forecast using harmonic regression, you will need to generate the future values of the Fourier terms. This can be done as follows.

fc <- forecast(fit, newdata=data.frame(fourier(x, K, h)))

where fit is the fitted model using tslm, K is the number of Fourier terms used in creating fit, and h is the forecast horizon required. Forecast the next year of data.
e. Plot the forecasts along with the actual data for 2005. What do you find?

7. Data set huron gives the water level of Lake Huron in feet from 1875-1972.

a. Plot the data and comment on its features.
b. Fit a linear regression and compare this to a piecewise linear trend model with a knot at 1915.
c. Generate forecasts from these two models for the period upto 1980 and comment on these.

### Question 4, 8 are related with math, not related with coding that I didn't include them in here.