# Chapter 7

```{r echo=FALSE, message=FALSE, warning=FALSE, Load_packages}

library(fpp2)
library(seasonal)

```

1. Consider the pigs series - the number of pigs slaughtered in Victoria each month.
 Use the ses function in R to find the optimal values of alpha and l0, and generate forecasts for the next four months.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question1}

str(pigs)
head(pigs)

ses_pigs <- ses(pigs, h = 4)

# how SES model fitted
ses_pigs$model

# 95% prediction interval for the first forecast
ses_pigs$upper[1, "95%"]
ses_pigs$lower[1, "95%"]

# calculate 95% prediction interval using formula
s <- sd(ses_pigs$residuals)
ses_pigs$mean[1] + 1.96*s
ses_pigs$mean[1] - 1.96*s
# even though small compared to the data scale, the results were a little different from the results of ses function. I don't know why.

# plot the data, fitted values and forecasts.
autoplot(ses_pigs) +
  autolayer(ses_pigs$fitted)

```


2. Write your own function to implement simple exponential smoothing. The function should take arguments y (the time series), alpha (the smoothing parameter alpha) and level (the initial level l0). It should return the forecast of the next observation in the series. Does it give the same forecast as ses?

```{r echo=FALSE, message=FALSE, warning=FALSE, Question2}

# make SES function
SES <- function(y, alpha, l0){
  y_hat <- l0
  for(index in 1:length(y)){
   y_hat <- alpha*y[index] + (1 - alpha)*y_hat 
  }
  cat("Forecast of next observation by SES function: ",
      as.character(y_hat),
      sep = "\n")
}

# compare ses and SES using pigs data
alpha <- ses_pigs$model$par[1]
l0 <- ses_pigs$model$par[2]

SES(pigs, alpha = alpha, l0 = l0)

writeLines(paste(
  "Forecast of next observation by ses function: ",       as.character(ses_pigs$mean[1])
  ))

# compare ses and SES using ausbeer data
ses_ausbeer <- ses(ausbeer, h = 1)
alpha <- ses_ausbeer$model$par[1]
l0 <- ses_ausbeer$model$par[2]

SES(ausbeer, alpha = alpha, l0 = l0)

writeLines(paste(
  "Forecast of next observation by ses function: ",       as.character(ses_ausbeer$mean[1])
  ))

# found that SES function, which I made worked same as ses function.

```


3. Modify your function from the previous exercise to return the sum of squared errors rather than the forecast of the next observation. Then use the optim function to find the optimal values of alpha and l0. Do you get the same values as the ses function?

```{r echo=FALSE, message=FALSE, warning=FALSE, Question3}

# modify SES function to return SSE
SES <- function(pars = c(alpha, l0), y){
  # change the first argument as vector of alpha and l0, rather than alpha and l0 each because optim function wants the function in function argument to have the first argument as vector.
  error <- 0
  SSE <- 0
  alpha <- pars[1]
  l0 <- pars[2]
  y_hat <- l0
  
  for(index in 1:length(y)){
    error <- y[index] - y_hat
    SSE <- SSE + error^2
    
    y_hat <- alpha*y[index] + (1 - alpha)*y_hat 
  }
  
  return(SSE)
}

# compare ses and SES using pigs data
# set initial values as alpha = 0.5 and l0 = first observation value of data.
opt_SES_pigs <- optim(par = c(0.5, pigs[1]), y = pigs, fn = SES)

writeLines(paste(
  "Optimal parameters for the result of SES function: ",
  "\n",
  as.character(opt_SES_pigs$par[1]),
  ", ",
  as.character(opt_SES_pigs$par[2]),
  sep = ""
  ))

writeLines(paste(
  "Parameters got from the result of ses function: ",
  "\n",
  as.character(ses_pigs$model$par[1]),
  ", ",
  as.character(ses_pigs$model$par[2]),
  sep = ""
))
# In this case, alphas were almost same, but l0s were different. I think that it happened because the scale l0 is big.

# compare ses and SES using ausbeer data
# set initial values as alpha = 0.5 and l0 = first observation value of data.
opt_SES_ausbeer <- optim(par = c(0.5, ausbeer[1]), y = ausbeer, fn = SES)

writeLines(paste(
  "Optimal parameters for the result of SES function: ",
  "\n",
  as.character(opt_SES_ausbeer$par[1]),
  ", ",
  as.character(opt_SES_ausbeer$par[2]),
  sep = ""
  ))

writeLines(paste(
  "Parameters got from the result of ses function: ",
  "\n",
  as.character(ses_ausbeer$model$par[1]),
  ", ",
  as.character(ses_ausbeer$model$par[2]),
  sep = ""
))
# In this case, alphas were almost same regardless of used functions. And the same result for l0s.

```


4. Combine your previous two functions to produce a function which both finds the optimal values of alpha and  
l0, and produces a forecast of the next observation in the series.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question4}

# modify SES function to find the optimal values of alpha and l0, and produce the next observation forecast.
SES <- function(init_pars, data){
  # init_pars is c(init_alpha, init_l0)

  # make next observation forecast variable
  fc_next <- 0
  
  # make SSE function to get SSE if parameters and data are given.
  SSE <- function(pars, data){
    error <- 0
    SSE <- 0
    alpha <- pars[1]
    l0 <- pars[2]
    y_hat <- l0
    
    for(index in 1:length(data)){
      error <- data[index] - y_hat
      SSE <- SSE + error^2
      
      y_hat <- alpha*data[index] + (1 - alpha)*y_hat 
    }
    # use superassignment to make forecast value possible to use outside SSE function.
    fc_next <<- y_hat
    return(SSE)
  }
  
  # use optim function to get optimal values of alpha and l0.
  optim_pars <- optim(par = init_pars, data = data, fn = SSE)
  
  # return results
  return(list(
    Next_observation_forecast = fc_next,
    alpha = optim_pars$par[1],
    l0 = optim_pars$par[2]
    ))
}

# compare the result using pigs data
SES(c(0.5, pigs[1]), pigs)

print("Next observation forecast by ses function")
ses_pigs$mean[1]

print("alpha calculated by ses function")
ses_pigs$model$par[1]

print("l0 calculated by ses function")
ses_pigs$model$par[2]

# compare the result using ausbeer data
SES(c(0.5, ausbeer[1]), ausbeer)

print("Next observation forecast by ses function")
ses_ausbeer$mean[1]

print("alpha calculated by ses function")
ses_ausbeer$model$par[1]

print("l0 calculated by ses function")
ses_ausbeer$model$par[2]

# SES function worked similar to ses function.

```

5. Data set books contains the daily sales of paperback and hardcover books at the same store. The task is to forecast the next four days' sales for paperback and hardcover books.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question5}

# a. Plot the series and discuss the main features of the data.
str(books)
head(books)

autoplot(books)
# The sales of paperback and hardcover books generally increased as time went on with lots of fluctions. But the fluctuations don't show particular frequency that they can be thought of as cycle.

# b. Use the ses function to forecast each series, and plot the forecasts.
ses_paperback <- ses(books[, "Paperback"], h = 4)
ses_hardcover <- ses(books[, "Hardcover"], h = 4)

autoplot(books[, "Paperback"], series = "Paperback") +
  autolayer(ses_paperback, series = "Paperback") +
  autolayer(books[, "Hardcover"], series = "Hardcover") +
  autolayer(ses_hardcover, series = "Hardcover", PI = FALSE) +
  ylab("Sales amount") +
  ggtitle("Sales of paperback and hardcover books")
# can see the flat forecast by ses method.

# c. Compute the RMSE values for the training data in each case.
sqrt(mean(ses_paperback$residuals^2))
sqrt(mean(ses_hardcover$residuals^2))
# RMSE values for the training data show that the variance of the residuals of hardcover sales was smaller than the one of paperback sales.

```


6. 
```{r echo=FALSE, message=FALSE, warning=FALSE, Question6}

# a. Now apply Holt's linear method to the paperback and hardback series and compute four-day forecasts in each case.
holt_paperback <- holt(books[, "Paperback"], h = 4)
holt_hardcover <- holt(books[, "Hardcover"], h = 4)

autoplot(books[, "Paperback"]) +
  autolayer(holt_paperback)

autoplot(books[, "Hardcover"]) +
  autolayer(holt_hardcover)
# can see the linear trend in the forecasts.

# b. Compare the RMSE measures of Holt's method for the two series to those of simple exponential smoothing in the previous question. (Remember that Holt's method is using one more parameter than SES.) Discuss the merits of the two forecasting methods for these data sets.
s_paperback <- sqrt(mean(holt_paperback$residuals^2))
s_hardcover <- sqrt(mean(holt_hardcover$residuals^2))

s_paperback
s_hardcover
# For both series, RMSE values became lower when Holt's method was used.
# If there is linearly approximable trend in data, it would be better to use Holt's linear method even if use one more parameter than SES. But if there isn't any particular trend in data, it would be better to use SES method to make the model simpler.

# c. Compare the forecasts for the two series using both methods. Which do you think is best?
# I think that the forecasts of hardcover sales were better than the ones of paperback sales. Because RMSE value is lower, and the forecasts of paperback sales couldn't reflect the pattern in the data using Holt's method.

# d. Calculate a 95% prediction interval for the first forecast for each series, using the RMSE values and assuming normal errors. Compare your intervals with those produced using ses and holt.
writeLines("95% PI of paperback sales calculated by holt function")
holt_paperback$upper[1, "95%"]
holt_paperback$lower[1, "95%"]

writeLines("95% PI of paperback sales calculated by formula")
holt_paperback$mean[1] + 1.96*s_paperback
holt_paperback$mean[1] - 1.96*s_paperback

writeLines("95% PI of hardcover sales calculated by holt function")
holt_hardcover$upper[1, "95%"]
holt_hardcover$lower[1, "95%"]

writeLines("95% PI of hardcover sales calculated by formula")
holt_hardcover$mean[1] + 1.96*s_hardcover
holt_hardcover$mean[1] - 1.96*s_hardcover
# In this case, the prediction interval for the first forecast for each series was almost same regardless of calculating method. It is different from the ses case, in which the PI was different when it was calculated respectively by ses function and formula.

```


7. For this exercise use data set eggs, the price of a dozen eggs in the United States from 1900-1993. Experiment with the various options in the holt() function to see how much the forecasts change with damped trend, or with a Box-Cox transformation. Try to develop an intuition of what each argument is doing to the forecasts.

[Hint: use h=100 when calling holt() so you can clearly see the differences between the various options when plotting the forecasts.]

Which model gives the best RMSE?

```{r echo=FALSE, message=FALSE, warning=FALSE, Question7}

str(eggs)
head(eggs)

autoplot(eggs)
# see downward trend of the price of dozen eggs in US.
# I expect that using holt function with damped = TRUE and Box-Cox options will yield best forecasts. Because I think that the price of eggs will decrease slower as the price is going to near 0 and there's a need to make the size of the seasonal variation smaller for bigger prices.

# First, just use holt function without using any options.
holt_eggs <- holt(eggs, h = 100)
autoplot(holt_eggs) +
  autolayer(holt_eggs$fitted)
# Unrealistic because the price is predicted to be below 0.

# Second, use holt function with using damped option.
holt_damped_eggs <- holt(eggs, damped = TRUE, h = 100)
autoplot(holt_damped_eggs) +
  autolayer(holt_damped_eggs$fitted)
# Now, the predicted price don't go below 0, but point forecasts didn't reflect the already existed trend.

# Third, use holt function with using Box-Cox transformation.
holt_BoxCox_eggs <- holt(eggs, 
                         lambda = BoxCox.lambda(eggs), 
                         h = 100)
autoplot(holt_BoxCox_eggs) +
  autolayer(holt_BoxCox_eggs$fitted)
# Now, the point forecasts didn't go below 0 and reflected the already existed trend.

# Fourth, use holt function with using Box-Cox transformation and damped option.
holt_BoxCox_damped_eggs <- holt(
  eggs, 
  damped = TRUE,
  lambda = BoxCox.lambda(eggs),
  h = 100)
autoplot(holt_BoxCox_damped_eggs) +
  autolayer(holt_BoxCox_damped_eggs$fitted)
# The point forecasts didn't go below 0 and still decreasing but it didn't reflect the already existed trend well. Least part of prediction intervals were below 0.

# show RMSE values for each model
writeLines("RMSE when using holt function")
sqrt(mean(holt_eggs$residuals^2))

writeLines("RMSE when using holt function with damped option")
sqrt(mean(holt_damped_eggs$residuals^2))

writeLines("RMSE when using holt function with Box-Cox transformation")
sqrt(mean(holt_BoxCox_eggs$residuals^2))

writeLines("RMSE when using holt function with damped option and Box-Cox transformation")
sqrt(mean(holt_BoxCox_damped_eggs$residuals^2))

# BoxCox transformation captures trend and reflects it to the forecasts. Therefore it improves accuracy of the model. Holt's method with damped option just prohibits the forecasts to be below 0, not much improving accuracy for fitting the original data part.

# The best model was the Box-Cox transformation with Holt's linear method. It gave plausible point forecasts and prediction intervals. For 100 years prediction, Box-Cox transformation did enough damping effect. With damping option together, the point forecast couldn't follow the already existed trend.

```


8. Recall your retail time series data (from Exercise 3 in Section 2.10).

```{r echo=FALSE, message=FALSE, warning=FALSE, Question8}

# load the data
retail <- xlsx::read.xlsx("retail.xlsx",
                          sheetIndex = 1,
                          startRow = 2)

ts_retail <- ts(retail[, "A3349873A"],
                frequency = 12,
                start = c(1982, 4))

# a. Why is multiplicative seasonality necessary for this series?
autoplot(ts_retail)
# the data shows that the seasonality increased when the retail sales increased. Multiplicative seasonality can reflect the situation in the model, while additive seasonality can't.

# b. Apply Holt-Winters' multiplicative method to the data. Experiment with making the trend damped.
ets_AAM_retail <- hw(ts_retail,
                     seasonal = "multiplicative")

ets_AAdM_retail <- hw(ts_retail,
                      seasonal = "multiplicative",
                      damped = TRUE)

autoplot(ets_AAM_retail)
autoplot(ets_AAdM_retail)
# The forecasts increased slower when used damped option than when did not.

# c. Compare the RMSE of the one-step forecasts from the two methods. Which do you prefer?
error_ets_AAM_retail <- tsCV(
  ts_retail, 
  hw, h = 1, seasonal = "multiplicative"
  )

error_ets_AAdM_retail <- tsCV(
  ts_retail, 
  hw, h = 1, seasonal = "multiplicative", damped = TRUE
  )

sqrt(mean(error_ets_AAM_retail^2, na.rm = TRUE))
sqrt(mean(error_ets_AAdM_retail^2, na.rm = TRUE))
# When compared the RMSE values, they were almost same. Therefore I prefer damped model because it will prohibit the limitless increase of sales forecast.

# d. Check that the residuals from the best method look like white noise.
checkresiduals(ets_AAdM_retail)
# Unfortunately, the residuals from the best method don't look like white noise. Ljung-Box test result and ACF plot show that the residuals aren't white noise.

# e. Now find the test set RMSE, while training the model to the end of 2010. Can you beat the seasonal naïve approach from Exercise 7 in Section 3.7?
ts_retail_train <- window(ts_retail,
                          end = c(2010, 12))
ts_retail_test <- window(ts_retail,
                         start = 2011)

ets_AAdM_retail_train <- hw(ts_retail_train,
                            h = 36,
                            seasonal = "multiplicative",
                            damped = TRUE)

autoplot(ets_AAdM_retail_train)
accuracy(ets_AAdM_retail_train, ts_retail_test)
# When I used Holt-Winters' method with damped option, I couldn't beat seasonal naive approach. But when I used Holt-Winters' method without damped option, I could get better accuracy, but still couldn't beat the seasonal naive approach. 

# try Holt-Winters' method.
ets_AAM_retail_train <- hw(ts_retail_train,
                           h = 36,
                           seasonal = "multiplicative")

autoplot(ets_AAM_retail_train)
accuracy(ets_AAM_retail_train, ts_retail_test)
# In this case, damped Holt-Winters' method was worse than Holt-Winters' method because in the forecast horizon, the sales was exponentially increasing, not damping. I think that this case reflects the fact that the assumption behind the chosen forecast method should be right to forecast more accurately.

```


9. For the same retail data, try an STL decomposition applied to the Box-Cox transformed series, followed by ETS on the seasonally adjusted data. How does that compare with your best previous forecasts on the test set?

```{r echo=FALSE, message=FALSE, warning=FALSE, Question9}

#stl_ets_retail_train <- ts_retail_train %>% 
#  stl(s.window = 13, robust = TRUE) %>% 
#  forecast(method = "ets", 
#           h = 36,
#           lambda = BoxCox.lambda(ts_retail_train))
# Fitted values and forecasts of above code yields multiple squared values. It looked like the lambda in forecast function just do back-transform, not do transform and back-transform both. I wonder if the forecast function assumes that the object entered is already transformed if needed.

stl_ets_retail_train <- ts_retail_train %>%
  stlm(
    #made stl model first
    s.window = 13,
    robust = TRUE,
    #designate that the seasonally adjusted data should be forecasted by ETS method.
    method = "ets",
    lambda = BoxCox.lambda(ts_retail_train)
  ) %>%
  #forecast using stl model
  forecast(h = 36)
# I didn't need to use seasadj function because forecasts of STL objects are applying non-seasonal forecasting method to the seasonally adjusted data automatically.

autoplot(stl_ets_retail_train)
accuracy(stl_ets_retail_train, ts_retail_test)
# STL decomposition with Box-Cox transformation and ETS forecasting yielded better result than when ETS(A, Ad, M) was used. But the method was a little worse than ETS(A, A, M). Of course, it couldn't beat seasonal naive method.

# try forecasting without doing transformation.
stl_ets_retail_train_without_tr <- ts_retail_train %>%
  stlm(
    s.window = 13,
    robust = TRUE,
    method = "ets"
  ) %>%
  forecast(h = 36)

autoplot(stl_ets_retail_train_without_tr)
accuracy(stl_ets_retail_train_without_tr, ts_retail_test)
# Without doing transformation, when I got accuracy using test set I got better result. But I couldn't expect it because when I did transformation too, the accuracy of training set was better. Real datas in forecast horizon increased exponentially. Without using transformation, the forecast could reflect the fact that the bigger values have bigger variation and it was useful at forecasting at the time.

# STL decomposition 'without' Box-Cox transformation and ETS forecasting yielded better result than when ETS(A, Ad, M) or ETS(A, A, M) was used. But the method also  couldn't beat seasonal naive method.

```

10. For this exercise use data set ukcars, the quarterly UK passenger vehicle production data from 1977Q1-2005Q1.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question10}

# a. Plot the data and describe the main features of the series.
str(ukcars)
head(ukcars)

autoplot(ukcars)
# The data has trend and quarterly seasonality.

# b. Decompose the series using STL and obtain the seasonally adjusted data.
seasadj_ukcars <- ukcars %>% stl(s.window = 4, robust = TRUE) %>% seasadj() 

autoplot(seasadj_ukcars)
# decreased much variations.

# c. Forecast the next two years of the series using an additive damped trend method applied to the seasonally adjusted data. (This can be done in one step using stlf with arguments etsmodel="AAN", damped=TRUE.
stl_ets_AAdN_ukcars <- ukcars %>% stlf(h = 8, etsmodel = "AAN", damped = TRUE)

autoplot(stl_ets_AAdN_ukcars)

# d. Forecast the next two years of the series using Holt's linear method applied to the seasonally adjusted data (as before but with damped=FALSE).
stl_ets_AAN_ukcars <- ukcars %>% stlf(h = 8, etsmodel = "AAN", damped = FALSE)

autoplot(stl_ets_AAN_ukcars)

# e. Now use ets() to choose a seasonal model for the data.
ets_ukcars <- ets(ukcars)
summary(ets_ukcars)
# got ETS(A, N, A) model.

autoplot(forecast(ets_ukcars, h = 8))

# f. Compare the RMSE of the ETS model with the RMSE of the models you obtained using STL decompositions. Which gives the better in-sample fits?
writeLines("")
print("Accuracy of STL + ETS(A, Ad, N) model")
accuracy(stl_ets_AAdN_ukcars)
print("Accuracy of STL + ETS(A, A, N) model")
accuracy(stl_ets_AAN_ukcars)
print("Accuracy of ETS(A, N, A) model")
accuracy(ets_ukcars)
# STL + ETS(A, Ad, N) was the best model.

# g. Compare the forecasts from the three approaches? Which seems most reasonable?
# I think that the forecasts from the STL + ETS(A, Ad, N) were the most reasonable ones. I think so because the forecasts reflected the not-increasing and smaller-variation trend after the fall of 2001 best.

# h. Check the residuals of your preferred model.
checkresiduals(stl_ets_AAdN_ukcars)
# There are still some autocorrelations in the residuals. And they don't look like normally distributed.

```


11. For this exercise use data set visitors, the monthly Australian short-term overseas visitors data, May 1985-April 2005.

```{r echo=FALSE, message=FALSE, warning=FALSE, Question11}

# a. Make a time plot of your data and describe the main features of the series.
str(visitors)
head(visitors)

autoplot(visitors)
# Can see general increasing trend and monthly seasonality. And also can find the dramatic in May, 2003.

# b. Split your data into a training set and a test set comprising the last two years of available data. Forecast the test set using Holt-Winters' multiplicative method.
visitors_train <- subset(visitors, 
                         end = length(visitors) - 24)
visitors_test <- subset(visitors,
                        start = length(visitors) - 23)

hw_mul_visitors_train <- hw(visitors_train,
                            h = 24,
                            seasonal = "multiplicative")

# c. Why is multiplicative seasonality necessary here?
autoplot(hw_mul_visitors)
# Can see that the seasonality effect increased as the number of visitors increased. Additive seasonality can't reflect the situation to the model and to the forecast.

# d. Forecast the two-year test set using each of the following methods:

# d-1. an ETS model;
fc_ets_visitors_train <- forecast(ets(visitors_train), h = 24)

autoplot(fc_ets_visitors_train)

# d-2. an additive ETS model applied to a Box-Cox transformed series;
fc_ets_add_BoxCox_visitors_train <- forecast(
  ets(visitors_train, 
      lambda = BoxCox.lambda(visitors_train),
      additive.only = TRUE),
  h = 24
)

autoplot(fc_ets_add_BoxCox_visitors_train)

# d-3. a seasonal naive method;
fc_snaive_visitors_train <- snaive(visitors_train, h = 24)

autoplot(fc_snaive_visitors_train)

# d-4. an STL decomposition applied to the Box-Cox transformed data followed by an ETS model applied to the seasonally adjusted (transformed) data.
fc_BoxCox_stl_ets_visitors_train <- visitors_train %>%
  stlm(
    lambda = BoxCox.lambda(visitors_train),
    s.window = 13,
    robust = TRUE,
    method = "ets"
  ) %>%
  forecast(h = 24)

autoplot(fc_BoxCox_stl_ets_visitors_train)

# e. Which method gives the best forecasts? Does it pass the residual tests?
accuracy(hw_mul_visitors_train, visitors_test)
accuracy(fc_ets_visitors_train, visitors_test)
accuracy(fc_ets_add_BoxCox_visitors_train, visitors_test)
accuracy(fc_snaive_visitors_train, visitors_test)
accuracy(fc_BoxCox_stl_ets_visitors_train, visitors_test)
# the order of models according to accuracy using test set:
# snaive > additive ETS with BoxCox transformation - ETS(A, A, A) > STL + ETS(M, A, N) with BoxCox transformation > ETS (M, Ad, M) > Holt-Winters' multiplicative method

# f. Compare the same five methods using time series cross-validation with the tsCV function instead of using a training and test set. Do you come to the same conclusions?
# first, make functions to make model to yield forecast class object
fets_add_BoxCox <- function(y, h) {
  forecast(ets(
    y,
    lambda = BoxCox.lambda(y),
    additive.only = TRUE
  ),
  h = h)
}
fstlm <- function(y, h) {
  forecast(stlm(
    y, 
    lambda = BoxCox.lambda(y),
    s.window = frequency(y) + 1,
    robust = TRUE,
    method = "ets"
  ),
  h = h)
}
fets <- function(y, h) {
  forecast(ets(y),
           h = h)
  }

# I'll compare the models using RMSE
sqrt(mean(tsCV(visitors, snaive, h = 1)^2, na.rm = TRUE))
sqrt(mean(tsCV(visitors, fets_add_BoxCox, h = 1)^2,
          na.rm = TRUE))
sqrt(mean(tsCV(visitors, fstlm, h = 1)^2,
          na.rm = TRUE))
sqrt(mean(tsCV(visitors, fets, h = 1)^2, na.rm = TRUE))
sqrt(mean(tsCV(visitors, hw, h = 1, 
               seasonal = "multiplicative")^2,
          na.rm = TRUE))
# tsCV errors show that the best model is the STL + ETS(M, A, N) model and the worst model is seasonal naive model. If I didn't get accuracy using test set, I couldn't know that the forecasts from seasonal naive method were the most accurate ones.

```


12. The fets function below returns ETS forecasts.

  fets <- function(y, h) {
  forecast(ets(y), h = h)
  }

a. Apply tsCV() for a forecast horizon of h=4, for both ETS and seasonal naive methods to the cement data, XXX. (Hint: use the newly created fets and the existing snaive functions as your forecast function arguments.)
b. Compute the MSE of the resulting 4-steps-ahead errors. (Hint: make sure you remove missing values.) Why is there missing values? Comment on which forecasts are more accurate. Is this what you expected?

### cement data isn't time series data. And it looked like the data isn't related with time, too. Therefore I'll skip this question.
### I can get numerator of MASE by tsCV and denominator of MASE by 1/(length(y) - k)*sum(abs(lag(y, k = -m) - y)).

13. Compare ets, snaive and stlf on the following six time series. For stlf, you might need to use a Box-Cox transformation. Use a test set of three years to decide what gives the best forecasts. ausbeer, bricksq, dole, a10, h02, usmelec.

14. 
a. Use ets() on the following series:

bicoal, chicken, dole, usdeaths, lynx, ibmclose, eggs.

Does it always give good forecasts?

b. Find an example where it does not work well. Can you figure out why?